{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for Natural Language  Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "# feature extractioin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# classification models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Hyperparameter tunning methods\n",
    "#import parfit.parfit as pf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Metrics for Model Evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from scikitplot.metrics import plot_roc, plot_confusion_matrix\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the data\n",
    "data_train = pd.read_csv(\"train_set.csv\")\n",
    "samp_sub = pd.read_csv(\"sample_submission.csv\")\n",
    "data_test = pd.read_csv(\"test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33000 entries, 0 to 32999\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   lang_id  33000 non-null  bool \n",
      " 1   text     33000 non-null  bool \n",
      "dtypes: bool(2)\n",
      "memory usage: 64.6 KB\n"
     ]
    }
   ],
   "source": [
    "#Checking if there are missing values in the Train dataset\n",
    "data_train.isna().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5682 entries, 0 to 5681\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   index   5682 non-null   bool \n",
      " 1   text    5682 non-null   bool \n",
      "dtypes: bool(2)\n",
      "memory usage: 11.2 KB\n"
     ]
    }
   ],
   "source": [
    "#Cheching if there are missing values in the Test dataset\n",
    "data_test.isna().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the available data\n",
    "df_test = data_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the train data\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nbl    3000\n",
       "sot    3000\n",
       "ssw    3000\n",
       "afr    3000\n",
       "nso    3000\n",
       "zul    3000\n",
       "xho    3000\n",
       "tso    3000\n",
       "ven    3000\n",
       "eng    3000\n",
       "tsn    3000\n",
       "Name: lang_id, dtype: int64"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the values of the language id:\n",
    "data_train[\"lang_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang_id    0\n",
       "text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for the null values in the dataset\n",
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta."
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the test data\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index lang_id\n",
       "0      1     tsn\n",
       "1      2     nbl"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the sample data, i.e. how we will have to submit...\n",
    "samp_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['xho', 'eng', 'nso', 'ven', 'tsn', 'nbl', 'zul', 'ssw', 'tso',\n",
       "       'sot', 'afr'], dtype=object)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the unique values of the train dataset language id\n",
    "data_train[\"lang_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the train dataset\n",
    "df = data_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32995</th>\n",
       "      <td>tsn</td>\n",
       "      <td>popo ya dipolateforomo tse ke go tlisa boetele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32996</th>\n",
       "      <td>sot</td>\n",
       "      <td>modise mosadi na o ntse o sa utlwe hore thaban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32997</th>\n",
       "      <td>eng</td>\n",
       "      <td>closing date for the submission of completed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>xho</td>\n",
       "      <td>nawuphina umntu ofunyenwe enetyala phantsi kwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32999</th>\n",
       "      <td>sot</td>\n",
       "      <td>mafapha a mang le ona a lokela ho etsa ditlale...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lang_id                                               text\n",
       "0         xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1         xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2         eng  the province of kwazulu-natal department of tr...\n",
       "3         nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4         ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...\n",
       "...       ...                                                ...\n",
       "32995     tsn  popo ya dipolateforomo tse ke go tlisa boetele...\n",
       "32996     sot  modise mosadi na o ntse o sa utlwe hore thaban...\n",
       "32997     eng  closing date for the submission of completed t...\n",
       "32998     xho  nawuphina umntu ofunyenwe enetyala phantsi kwa...\n",
       "32999     sot  mafapha a mang le ona a lokela ho etsa ditlale...\n",
       "\n",
       "[33000 rows x 2 columns]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the copy \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate features and tagret variables\n",
    "y = df['lang_id']\n",
    "X = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning text into something your model can read\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=2)\n",
    "X_vectorized = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train data to create validation dataset\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_vectorized,y,test_size=.3,shuffle=True, stratify=y, random_state=11)#changed test size to 0.1 from 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9956565656565657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       900\n",
      "         eng       1.00      1.00      1.00       900\n",
      "         nbl       0.99      0.99      0.99       900\n",
      "         nso       1.00      1.00      1.00       900\n",
      "         sot       1.00      1.00      1.00       900\n",
      "         ssw       0.99      1.00      0.99       900\n",
      "         tsn       1.00      1.00      1.00       900\n",
      "         tso       1.00      1.00      1.00       900\n",
      "         ven       1.00      1.00      1.00       900\n",
      "         xho       0.99      0.99      0.99       900\n",
      "         zul       0.99      0.98      0.98       900\n",
      "\n",
      "    accuracy                           1.00      9900\n",
      "   macro avg       1.00      1.00      1.00      9900\n",
      "weighted avg       1.00      1.00      1.00      9900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1000, multi_class='ovr', solver='saga', random_state=42, max_iter=10)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_val)\n",
    "logreg_f1 = round(f1_score(y_val, y_pred, average='weighted'),2)\n",
    "print('Accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "\n",
    "report = classification_report(y_val, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the and Take it to Kaggle\n",
    "test_logreg = data_test['text']\n",
    "test_vect = vectorizer.transform(test_logreg)\n",
    "# Predict the sentiment using the test data\n",
    "y_pred = logreg.predict(test_vect)\n",
    "# Assign a new column on the test data by using ...\n",
    "# the predicted sentiment from the tweets from test data\n",
    "data_test['lang_id'] = y_pred\n",
    "# Look into the data that will be submitted on Kaggle as csv\n",
    "data_test[['index', 'lang_id']].head()\n",
    "# save the csv file and submit it.\n",
    "data_test[['index', 'lang_id']].to_csv('test_logreg_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9957575757575757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       900\n",
      "         eng       1.00      1.00      1.00       900\n",
      "         nbl       0.99      0.98      0.99       900\n",
      "         nso       1.00      1.00      1.00       900\n",
      "         sot       1.00      1.00      1.00       900\n",
      "         ssw       0.99      1.00      1.00       900\n",
      "         tsn       1.00      1.00      1.00       900\n",
      "         tso       1.00      1.00      1.00       900\n",
      "         ven       1.00      1.00      1.00       900\n",
      "         xho       1.00      0.99      0.99       900\n",
      "         zul       0.98      0.99      0.98       900\n",
      "\n",
      "    accuracy                           1.00      9900\n",
      "   macro avg       1.00      1.00      1.00      9900\n",
      "weighted avg       1.00      1.00      1.00      9900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_features=4, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "rf_f1 = round(f1_score(y_val, y_pred, average='weighted'),2)\n",
    "print('Accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "\n",
    "report = classification_report(y_val, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the csv model for the random Forest model and take it to Kaggle\n",
    "test_rf = data_test['text']\n",
    "test_vect = vectorizer.transform(test_logreg)\n",
    "# Predict the sentiment using the test data\n",
    "yrf_pred = rf.predict(test_vect)\n",
    "# Assign a new column on the test data by using ...\n",
    "# the predicted sentiment from the tweets from test data\n",
    "data_test['lang_id'] = yrf_pred\n",
    "# Look into the data that will be submitted on Kaggle as csv\n",
    "data_test[['index', 'lang_id']].head()\n",
    "# save the csv file and submit it.\n",
    "data_test[['index', 'lang_id']].to_csv('test_RandomForest_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve the LR model using the GridVSearch\n",
    "param_grid = {'C': [1000], #[100,1000]\n",
    "              'max_iter': [100], #[10,100]\n",
    "              'multi_class': ['multinomial'], #['ovr', 'multinomial']\n",
    "              'random_state': [42],\n",
    "              'solver': ['lbfgs']} #['saga','lbfgs']\n",
    "grid_LR = GridSearchCV(LogisticRegression(), param_grid, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "grid_LR.fit(X_train, y_train)\n",
    "y_pred = grid_LR.predict(X_val)\n",
    "print(\"Best parameters:\")\n",
    "lr_params = grid_LR.best_params_\n",
    "print(grid_LR.best_params_)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Grid V\n",
    "test_lrh = data_test['text']\n",
    "test_vect = vectorizer.transform(test_lrh)\n",
    "# Predict the sentiment using the test data\n",
    "ylrh_pred = grid_LR.predict(test_vect)\n",
    "# Assign a new column on the test data by using ...\n",
    "# the predicted sentiment from the tweets from test data\n",
    "data_test['lang_id'] = ylrh_pred\n",
    "# Look into the data that will be submitted on Kaggle as csv\n",
    "data_test[['index', 'lang_id']].head()\n",
    "# save the csv file and submit it.\n",
    "data_test[['index', 'lang_id']].to_csv('test_lrhp_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVC_param_grid = {'LSVC_clf__C': [1, 1.01, 1.02, 1.03],\n",
    "                   'LSVC_tfidf__max_df': (0.9, 0.999),\n",
    "                   'LSVC_tfidf__min_df': (0,0.00001, 0.001),\n",
    "                   'LSVC_tfidf__ngram_range': [(1, 2), (1, 3), (1, 4), (1, 5)]}\n",
    "\n",
    "\n",
    "# Using the Linear SVC model above, we perform the gridsearch\n",
    "LSVC_searchCV = GridSearchCV(LinearSVC(), cv=5, param_grid=LSVC_param_grid, verbose=3, scoring='f1_weighted', n_jobs=-1, refit=True)\n",
    "LSVC_searchCV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_LSVC= data_test['text']\n",
    "test_vect = vectorizer.transform(test_LSVC)\n",
    "# Predict the sentiment using the test data\n",
    "yLSVC_pred = grid_LSVC.predict(test_vect)\n",
    "# Assign a new column on the test data by using ...\n",
    "# the predicted sentiment from the tweets from test data\n",
    "data_test['lang_id'] = yLSVC_pred\n",
    "# Look into the data that will be submitted on Kaggle as csv\n",
    "data_test[['index', 'lang_id']].head()\n",
    "# save the csv file and submit it.\n",
    "data_test[['index', 'lang_id']].to_csv('test_LSVC_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearSVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svm = SVC(kernel='linear')\n",
    "# Fit the model\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_val)\n",
    "svm_f1 = round(f1_score(y_val, y_pred, average='weighted'),2)\n",
    "print('Accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "\n",
    "report = classification_report(y_val, y_pred)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "test_svm = data_test['text']\n",
    "test_vect = vectorizer.transform(test_svm)\n",
    "# Predict the sentiment using the test data\n",
    "ysvm_pred = svm.predict(test_vect)\n",
    "# Assign a new column on the test data by using ...\n",
    "# the predicted sentiment from the tweets from test data\n",
    "data_test['lang_id'] = ysvm_pred\n",
    "# Look into the data that will be submitted on Kaggle as csv\n",
    "data_test[['index', 'lang_id']].head()\n",
    "# save the csv file and submit it.\n",
    "data_test[['index', 'lang_id']].to_csv('test_svm_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha': [0.0001], 'max_iter': [1000],\n",
    "              'n_iter_no_change': [5], 'tol': [0.01]}\n",
    "grid_sgdc = GridSearchCV(SGDClassifier(), param_grid,\n",
    "                         scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "grid_sgdc.fit(X_train, y_train)\n",
    "y_pred = grid_sgdc.predict(X_val)\n",
    "sgdc_params = grid_sgdc.best_params_\n",
    "print(grid_sgdc.best_params_)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sgdc= data_test['text']\n",
    "test_vect = vectorizer.transform(test_sgdc)\n",
    "# Predict the sentiment using the test data\n",
    "ysgdc_pred = grid_sgdc.predict(test_vect)\n",
    "# Assign a new column on the test data by using ...\n",
    "# the predicted sentiment from the tweets from test data\n",
    "data_test['lang_id'] = ysgdc_pred\n",
    "# Look into the data that will be submitted on Kaggle as csv\n",
    "data_test[['index', 'lang_id']].head()\n",
    "# save the csv file and submit it.\n",
    "data_test[['index', 'lang_id']].to_csv('test_grid_sgdc_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "def preprocess(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    random_characters = ['â','¢','‚','¬','Â','¦','’',\"It's\",'Ã','..','Å']\n",
    "    #tokenizer = word_tokenize(preserve_case=True, reduce_len=True)\n",
    "    tweet = word_tokenize(tweet)\n",
    "    stopwords_list = set(random_characters+list(punctuation))\n",
    "    tweet = [word for word in tweet if word not in stopwords_list]\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', \" \".join(tweet))\n",
    "    tweet = re.sub(r'@([^\\s]+)', r'\\1', \"\".join(tweet))\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the labels and features\n",
    "train['processed'] = train['text'].apply(preprocess)\n",
    "X = train['processed']\n",
    "y = train['lang_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40: umgaqo-siseko wenza amalungiselelo kumaziko axhasa ulawulo lwesininzi kunye nokuthath inxaxheba kwabafazi ezi ziquka phakathi kwezinye zazo ikomishoni yokulingana ngokwesini ikomishoni yamalungelo oluntu lomzantsi afrika\n",
      "\n",
      "\n",
      "41: i-dha iya kuba nobulumko bokubeka umsebenzi naphi na kwisebe ngokusekwe kwiimfuno zokusebenza zalo emva kokubonana nomsebenzi kunye okanye imanyano yakhe ukuba ulandulo lomntu onjalo alufanelekanga i-dha mayibize uncedo olufanelekileyo elungelweni layo\n",
      "\n",
      "\n",
      "42: the province of kwazulu-natal department of transport invites tenders from established contractors experienced in bridge construction for the construction of the kwajolwayo tugela river pedestrian bridge near tugela ferry the duration of the project will be months\n",
      "\n",
      "\n",
      "43: o netefatša gore o ba file dilo ka moka tše le dumelelanego ka tšona mohlala maleri a magolo a a šomišwago go fihlelela meagong e metelele scaffolds a a bolokegilego lefelo la maleba la go šomela go phela gabotse bjbj\n",
      "\n",
      "\n",
      "44: khomishini ya ndinganyiso ya mbeu yo ewa maana u ya nga mulayo wa khomishini ya ndinganyiso ya mbeu u thetshelesa mbilaelo dzine dza tshimbilelana na tshialula u ya nga mbeu nahone i ivhea sa foramu ya thungo u ya nga mulayo wa ndinganyiso\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing out cleaned text\n",
    "index = 40\n",
    "for text in X[0:5]:\n",
    "    print(str(index)+\": \" + text)\n",
    "    print('\\n')\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: umgaqo-siseko wenza amalungiselelo kumaziko axhasa ulawulo lwesininzi kunye nokuthath inxaxheba kwabafazi ezi ziquka phakathi kwezinye zazo ikomishoni yokulingana ngokwesini ikomishoni yamalungelo oluntu lomzantsi afrika\n",
      "\n",
      "\n",
      "2: i-dha iya kuba nobulumko bokubeka umsebenzi naphi na kwisebe ngokusekwe kwiimfuno zokusebenza zalo emva kokubonana nomsebenzi kunye okanye imanyano yakhe ukuba ulandulo lomntu onjalo alufanelekanga i-dha mayibize uncedo olufanelekileyo elungelweni layo\n",
      "\n",
      "\n",
      "3: the province of kwazulu-natal department of transport invites tenders from established contractors experienced in bridge construction for the construction of the kwajolwayo tugela river pedestrian bridge near tugela ferry the duration of the project will be months\n",
      "\n",
      "\n",
      "4: o netefatša gore o ba file dilo ka moka tše le dumelelanego ka tšona mohlala maleri a magolo a a šomišwago go fihlelela meagong e metelele scaffolds a a bolokegilego lefelo la maleba la go šomela go phela gabotse bjbj\n",
      "\n",
      "\n",
      "5: khomishini ya ndinganyiso ya mbeu yo ewa maana u ya nga mulayo wa khomishini ya ndinganyiso ya mbeu u thetshelesa mbilaelo dzine dza tshimbilelana na tshialula u ya nga mbeu nahone i ivhea sa foramu ya thungo u ya nga mulayo wa ndinganyiso\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing out cleaned tweet\n",
    "index = 1\n",
    "for tweet in X[0:5]:\n",
    "    print(str(index)+\": \" + tweet)\n",
    "    print('\\n')\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta."
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df_test.copy()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess testing data by applying our function\n",
    "test['processed'] = test['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the labels and fetures into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a pipeline with a tfidf vectorizer and a logistic regression model\n",
    "LR_model = Pipeline([('tfidf',TfidfVectorizer()),('classify',(LogisticRegression(C=1.0,solver='lbfgs',random_state=42,max_iter=200)))])\n",
    "\n",
    "#fitting the model\n",
    "LR_model.fit(X_train, y_train)\n",
    "\n",
    "#Apply model on test data\n",
    "y_pred_lr = LR_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       150\n",
      "         eng       0.99      1.00      1.00       150\n",
      "         nbl       0.99      0.99      0.99       150\n",
      "         nso       1.00      0.99      1.00       150\n",
      "         sot       1.00      1.00      1.00       150\n",
      "         ssw       0.99      0.99      0.99       150\n",
      "         tsn       0.99      1.00      1.00       150\n",
      "         tso       1.00      1.00      1.00       150\n",
      "         ven       1.00      1.00      1.00       150\n",
      "         xho       1.00      0.99      1.00       150\n",
      "         zul       0.99      0.98      0.98       150\n",
      "\n",
      "    accuracy                           1.00      1650\n",
      "   macro avg       1.00      1.00      1.00      1650\n",
      "weighted avg       1.00      1.00      1.00      1650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the test dataset\n",
    "test_LR= test['processed']\n",
    "test_vect = vectorizer.transform(test_LR)\n",
    "# Predict the sentiment using the test data\n",
    "y_pred_lr = LR_model.predict(test_LR)\n",
    "# Assign a new column on the test data by using ...\n",
    "# the predicted sentiment from the tweets from test data\n",
    "data_test['lang_id'] =y_pred_lr\n",
    "# Look into the data that will be submitted on Kaggle as csv\n",
    "data_test[['index', 'lang_id']].head()\n",
    "# save the csv file and submit it.\n",
    "data_test[['index', 'lang_id']].to_csv('test_PipeLogisticR_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a pipeline with the tfid vectorizer and a linear svc model\n",
    "svc = Pipeline([('tfidf',TfidfVectorizer()),('classify',LinearSVC(C=1))])\n",
    "\n",
    "#fitting the model\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "#apply model on test data\n",
    "y_pred_svc = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       150\n",
      "         eng       0.99      1.00      0.99       150\n",
      "         nbl       0.99      0.99      0.99       150\n",
      "         nso       1.00      0.99      1.00       150\n",
      "         sot       0.99      1.00      1.00       150\n",
      "         ssw       0.99      1.00      1.00       150\n",
      "         tsn       0.99      0.99      0.99       150\n",
      "         tso       1.00      1.00      1.00       150\n",
      "         ven       1.00      1.00      1.00       150\n",
      "         xho       1.00      0.99      0.99       150\n",
      "         zul       0.99      0.99      0.99       150\n",
      "\n",
      "    accuracy                           1.00      1650\n",
      "   macro avg       1.00      1.00      1.00      1650\n",
      "weighted avg       1.00      1.00      1.00      1650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_svc= test['processed']\n",
    "test_vect = vectorizer.transform(test_LR)\n",
    "# Predict the sentiment using the test data\n",
    "y_pred_svc = svc.predict(test_svc)\n",
    "# Assign a new column on the test data by using ...\n",
    "# the predicted sentiment from the tweets from test data\n",
    "data_test['lang_id'] =y_pred_svc\n",
    "# Look into the data that will be submitted on Kaggle as csv\n",
    "data_test[['index', 'lang_id']].head()\n",
    "# save the csv file and submit it.\n",
    "data_test[['index', 'lang_id']].to_csv('test_svc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a pipeline with the DecisionTreeClassifier \n",
    "DT = Pipeline([('tfidf',TfidfVectorizer()),('classify',(DecisionTreeClassifier(max_depth=150,random_state=42, splitter='best')))])\n",
    "\n",
    "#fitting the model\n",
    "DT.fit(X_train, y_train)\n",
    "\n",
    "#Apply model on test data\n",
    "y_pred_DT = DT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       0.99      0.99      0.99       150\n",
      "         eng       0.98      1.00      0.99       150\n",
      "         nbl       0.86      0.85      0.86       150\n",
      "         nso       0.97      0.95      0.96       150\n",
      "         sot       0.97      0.99      0.98       150\n",
      "         ssw       0.94      0.85      0.90       150\n",
      "         tsn       0.95      0.94      0.95       150\n",
      "         tso       0.99      0.99      0.99       150\n",
      "         ven       0.99      0.99      0.99       150\n",
      "         xho       0.79      0.93      0.85       150\n",
      "         zul       0.86      0.79      0.83       150\n",
      "\n",
      "    accuracy                           0.93      1650\n",
      "   macro avg       0.94      0.93      0.93      1650\n",
      "weighted avg       0.94      0.93      0.93      1650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_DT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a pipeline with the RandomForest classifier  \n",
    "RF_model = Pipeline([('tfidf', TfidfVectorizer()),('clf', (RandomForestClassifier(max_depth=200, random_state=42,n_estimators=10)))])\n",
    "\n",
    "#fitting the model\n",
    "RF_model.fit(X_train, y_train)\n",
    "\n",
    "#Apply model on test data\n",
    "y_pred_RF = RF_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       150\n",
      "         eng       0.97      1.00      0.99       150\n",
      "         nbl       0.92      0.89      0.90       150\n",
      "         nso       0.99      0.97      0.98       150\n",
      "         sot       0.99      1.00      0.99       150\n",
      "         ssw       0.98      0.97      0.97       150\n",
      "         tsn       0.97      0.99      0.98       150\n",
      "         tso       1.00      1.00      1.00       150\n",
      "         ven       1.00      1.00      1.00       150\n",
      "         xho       0.90      0.97      0.93       150\n",
      "         zul       0.94      0.88      0.91       150\n",
      "\n",
      "    accuracy                           0.97      1650\n",
      "   macro avg       0.97      0.97      0.97      1650\n",
      "weighted avg       0.97      0.97      0.97      1650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['lang_id'].values\n",
    "X = train['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=5,\n",
    "# stop_words=\"english\")\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True,\n",
    "                             smooth_idf=True,\n",
    "                             max_df=0.3,\n",
    "                            # min_df=1,\n",
    "                             strip_accents='ascii',\n",
    "                             ngram_range=(1, 2))\n",
    "X_vectorized = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of the vectorised data: {}'.format(X_vectorized.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx = test['text']\n",
    "test_vect = vectorizer.transform(testx.values)\n",
    "test_vect.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing a variable to the desired SMOTE\n",
    "smote = SMOTE(random_state=2)#sampling_strategy='minority')\n",
    "\n",
    "# fit SMOTE to training dataset\n",
    "X_smote, y_smote = smote.fit_resample(X_vectorized, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_vectorized, y,\n",
    "                                                  #X_smote,y_smote,\n",
    "                                                  test_size=.1,\n",
    "                                                  random_state=42\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper tuned LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the range of 'C' parameters for LinearSVC\n",
    "params = {'C': [0.1, 0.5, 1, 5, 10]}\n",
    "\n",
    "# Setting the GridSearch for the best parameters\n",
    "clf = GridSearchCV(LinearSVC(max_iter=4000, multi_class='ovr'),\n",
    "                   param_grid=params, cv=kf,\n",
    "                   scoring=make_scorer(f1_score, average='macro'))\n",
    "\n",
    "# Fit the gridsearch on the dataset\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print('Getting the Best Model Performance' + '\\n')\n",
    "print('Accuracy: {}'.format(accuracy_score(y_val, y_pred)))\n",
    "print('F1: {}'.format(f1_score(y_val, y_pred, average='macro')))\n",
    "print('\\n' + classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx = test['text']\n",
    "test_vect = vectorizer.transform(testx.values)\n",
    "# Predict the sentiment using the test data\n",
    "y_pred = clf.predict(test_vect)\n",
    "# Assign a new column on the test data by using ...\n",
    "# the predicted sentiment from the tweets from test data\n",
    "test['lang_id'] = y_pred\n",
    "# Look into the data that will be submitted on Kaggle as csv\n",
    "test[['index', 'lang_id']].head()\n",
    "# save the csv file and submit it.\n",
    "test[['index', 'lang_id']].to_csv('test_LinearSVC_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complement Naive Bayes\n",
    "cnb = ComplementNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "y_pred = cnb.predict(X_val)\n",
    "\n",
    "print('Getting the Best Model Performance' + '\\n')\n",
    "print('Accuracy: {}'.format(accuracy_score(y_val, y_pred)))\n",
    "print('F1: {}'.format(f1_score(y_val, y_pred, average='macro')))\n",
    "print('\\n' + classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrying out cross-validation and checking F1 score for different classifiers\n",
    "random_state = 42\n",
    "kf = KFold(n_splits=10,\n",
    "           random_state=random_state,\n",
    "           shuffle=True)  # Define number of KFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': [0.1, 0.5, 1, 10],\n",
    "          'norm': [True, False]}\n",
    "\n",
    "clf2 = GridSearchCV(ComplementNB(),\n",
    "                    param_grid=params,\n",
    "                    cv=kf,\n",
    "                    scoring=make_scorer(f1_score,\n",
    "                                        average='macro'))\n",
    "# Fit the gridsearch on the dataset\n",
    "clf2 = clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf2.predict(X_val)\n",
    "\n",
    "print('Getting the Best Model Performance' + '\\n')\n",
    "print('Accuracy: {}'.format(accuracy_score(y_val, y_pred)))\n",
    "print('F1: {}'.format(f1_score(y_val, y_pred, average='macro')))\n",
    "print('\\n' + classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx = test['text']\n",
    "test_vect = vectorizer.transform(testx.values)\n",
    "# Predict the sentiment using the test data\n",
    "y_pred = clf2.predict(test_vect)\n",
    "# Assign a new column on the test data by using ...\n",
    "# the predicted sentiment from the tweets from test data\n",
    "test['lang_id'] = y_pred\n",
    "# Look into the data that will be submitted on Kaggle as csv\n",
    "test[['index', 'lang_id']].head()\n",
    "# save the csv file and submit it.\n",
    "test[['index', 'lang_id']].to_csv('test_ComplementNB_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnb = ComplementNB(alpha=clf2.best_params_['alpha'],\n",
    "                   norm=clf2.best_params_['norm'])\n",
    "cnb.fit(X_train, y_train)\n",
    "y_pred = cnb.predict(X_val)\n",
    "\n",
    "cnb_tuned = ComplementNB()\n",
    "cnb_tuned.fit(X_train, y_train)\n",
    "y_pred_tuned = cnb_tuned.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "testx = test['text']\n",
    "test_vect = vectorizer.transform(testx.values)\n",
    "# Predict the sentiment using the test data\n",
    "y_pred = cnb.predict(test_vect)\n",
    "# Assign a new column on the test data by using ...\n",
    "# the predicted sentiment from the tweets from test data\n",
    "test['lang_id'] = y_pred\n",
    "# Look into the data that will be submitted on Kaggle as csv\n",
    "test[['index', 'lang_id']].head()\n",
    "# save the csv file and submit it.\n",
    "test[['index', 'lang_id']].to_csv('test_ComplementNBtuned_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
