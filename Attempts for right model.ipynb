{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for Natural Language  Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "\n",
    "# Adding a comment\n",
    "\n",
    "\n",
    "# feature extractioin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# classification models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# Hyperparameter tunning methods\n",
    "#import parfit.parfit as pf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# metrics\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the train & test data sets\n",
    "train = pd.read_csv('train_set.csv')\n",
    "test = pd.read_csv('test_set.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33000 entries, 0 to 32999\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   lang_id  33000 non-null  bool \n",
      " 1   text     33000 non-null  bool \n",
      "dtypes: bool(2)\n",
      "memory usage: 64.6 KB\n"
     ]
    }
   ],
   "source": [
    "#Checking if there are missing values in the Train dataset\n",
    "train.isna().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5682 entries, 0 to 5681\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   index   5682 non-null   bool \n",
      " 1   text    5682 non-null   bool \n",
      "dtypes: bool(2)\n",
      "memory usage: 11.2 KB\n"
     ]
    }
   ],
   "source": [
    "#Cheching if there are missing values in the Test dataset\n",
    "test.isna().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part of Speech for modeling\n",
    "def POS(word):\n",
    "    \"\"\"\n",
    "    This function gets the part of speech\n",
    "    \"\"\"\n",
    "    pos_counts = Counter()\n",
    "    probable_part_of_speech = wordnet.synsets(word)\n",
    "    pos_counts[\"n\"] = len([i for i in probable_part_of_speech if i.pos()==\"n\"])\n",
    "    pos_counts[\"v\"] = len([i for i in probable_part_of_speech if i.pos()==\"v\"])\n",
    "    pos_counts[\"a\"] = len([i for i in probable_part_of_speech if i.pos()==\"a\"])\n",
    "    pos_counts[\"r\"] = len([i for i in probable_part_of_speech if i.pos()==\"r\"])\n",
    "    part_of_speech = pos_counts.most_common(1)[0][0]\n",
    "    return part_of_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text\n",
    "def text_lang(df):\n",
    "    '''\n",
    "    This function cleans the tweets by tokenizing, removing punctuation, \n",
    "    removing digits and removing 1 character tokens\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # tokenizing the tweets\n",
    "    text_lang = df['text'].apply(TweetTokenizer().tokenize) ## first we tokenize\n",
    "\n",
    "    # remove punctuation\n",
    "    text_lang = text_lang.apply(lambda x : [token for token in x if token not in string.punctuation])\n",
    "\n",
    "    # removing digits from the tweets\n",
    "    text_lang = text_lang.apply(lambda x: [token for token in x if token not in list(string.digits)])\n",
    "\n",
    "    # lastly we remove all one character tokens\n",
    "    text_lang = text_lang.apply(lambda x: [token for token in x if len(token) > 1])\n",
    "    \n",
    "    df['cleaned_text'] = text_lang\n",
    "    \n",
    "    return df['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [umgaqo-siseko, wenza, amalungiselelo, kumazik...\n",
       "1        [i-dha, iya, kuba, nobulumko, bokubeka, umsebe...\n",
       "2        [the, province, of, kwazulu-natal, department,...\n",
       "3        [netefatša, gore, ba, file, dilo, ka, moka, tš...\n",
       "4        [khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...\n",
       "                               ...                        \n",
       "32995    [popo, ya, dipolateforomo, tse, ke, go, tlisa,...\n",
       "32996    [modise, mosadi, na, ntse, sa, utlwe, hore, th...\n",
       "32997    [closing, date, for, the, submission, of, comp...\n",
       "32998    [nawuphina, umntu, ofunyenwe, enetyala, phants...\n",
       "32999    [mafapha, mang, le, ona, lokela, ho, etsa, dit...\n",
       "Name: cleaned_text, Length: 33000, dtype: object"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lang(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>[umgaqo-siseko, wenza, amalungiselelo, kumazik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>[i-dha, iya, kuba, nobulumko, bokubeka, umsebe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>[the, province, of, kwazulu-natal, department,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>[netefatša, gore, ba, file, dilo, ka, moka, tš...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>[khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32995</th>\n",
       "      <td>tsn</td>\n",
       "      <td>popo ya dipolateforomo tse ke go tlisa boetele...</td>\n",
       "      <td>[popo, ya, dipolateforomo, tse, ke, go, tlisa,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32996</th>\n",
       "      <td>sot</td>\n",
       "      <td>modise mosadi na o ntse o sa utlwe hore thaban...</td>\n",
       "      <td>[modise, mosadi, na, ntse, sa, utlwe, hore, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32997</th>\n",
       "      <td>eng</td>\n",
       "      <td>closing date for the submission of completed t...</td>\n",
       "      <td>[closing, date, for, the, submission, of, comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>xho</td>\n",
       "      <td>nawuphina umntu ofunyenwe enetyala phantsi kwa...</td>\n",
       "      <td>[nawuphina, umntu, ofunyenwe, enetyala, phants...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32999</th>\n",
       "      <td>sot</td>\n",
       "      <td>mafapha a mang le ona a lokela ho etsa ditlale...</td>\n",
       "      <td>[mafapha, mang, le, ona, lokela, ho, etsa, dit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lang_id                                               text  \\\n",
       "0         xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...   \n",
       "1         xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2         eng  the province of kwazulu-natal department of tr...   \n",
       "3         nso  o netefatša gore o ba file dilo ka moka tše le...   \n",
       "4         ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "...       ...                                                ...   \n",
       "32995     tsn  popo ya dipolateforomo tse ke go tlisa boetele...   \n",
       "32996     sot  modise mosadi na o ntse o sa utlwe hore thaban...   \n",
       "32997     eng  closing date for the submission of completed t...   \n",
       "32998     xho  nawuphina umntu ofunyenwe enetyala phantsi kwa...   \n",
       "32999     sot  mafapha a mang le ona a lokela ho etsa ditlale...   \n",
       "\n",
       "                                            cleaned_text  \n",
       "0      [umgaqo-siseko, wenza, amalungiselelo, kumazik...  \n",
       "1      [i-dha, iya, kuba, nobulumko, bokubeka, umsebe...  \n",
       "2      [the, province, of, kwazulu-natal, department,...  \n",
       "3      [netefatša, gore, ba, file, dilo, ka, moka, tš...  \n",
       "4      [khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...  \n",
       "...                                                  ...  \n",
       "32995  [popo, ya, dipolateforomo, tse, ke, go, tlisa,...  \n",
       "32996  [modise, mosadi, na, ntse, sa, utlwe, hore, th...  \n",
       "32997  [closing, date, for, the, submission, of, comp...  \n",
       "32998  [nawuphina, umntu, ofunyenwe, enetyala, phants...  \n",
       "32999  [mafapha, mang, le, ona, lokela, ho, etsa, dit...  \n",
       "\n",
       "[33000 rows x 3 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['lang_id'].values\n",
    "X = train['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=5,\n",
    "# stop_words=\"english\")\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True,\n",
    "                             smooth_idf=True,\n",
    "                             max_df=0.3,\n",
    "                            # min_df=1,\n",
    "                             strip_accents='ascii',\n",
    "                             ngram_range=(1, 2))\n",
    "X_vectorized = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the vectorised data: (33000, 710950)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the vectorised data: {}'.format(X_vectorized.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.334003  , 0.43226427, 0.23104263, ..., 0.57380339, 0.53319736,\n",
       "       0.19925329])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testx = test['text']\n",
    "test_vect = vectorizer.transform(testx.values)\n",
    "test_vect.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing a variable to the desired SMOTE\n",
    "smote = SMOTE(random_state=2)#sampling_strategy='minority')\n",
    "\n",
    "# fit SMOTE to training dataset\n",
    "X_smote, y_smote = smote.fit_resample(X_vectorized, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000, 710950)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000,)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_vectorized, y,\n",
    "                                                  #X_smote,y_smote,\n",
    "                                                  test_size=.1,\n",
    "                                                  random_state=42\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the Best Model Performance\n",
      "\n",
      "Accuracy: 0.996969696969697\n",
      "F1: 0.9970141197848694\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       0.99      1.00      1.00       281\n",
      "         eng       0.99      1.00      0.99       297\n",
      "         nbl       0.99      0.99      0.99       327\n",
      "         nso       1.00      1.00      1.00       322\n",
      "         sot       1.00      1.00      1.00       307\n",
      "         ssw       1.00      1.00      1.00       286\n",
      "         tsn       1.00      1.00      1.00       297\n",
      "         tso       1.00      1.00      1.00       253\n",
      "         ven       1.00      1.00      1.00       322\n",
      "         xho       1.00      1.00      1.00       313\n",
      "         zul       1.00      0.99      0.99       295\n",
      "\n",
      "    accuracy                           1.00      3300\n",
      "   macro avg       1.00      1.00      1.00      3300\n",
      "weighted avg       1.00      1.00      1.00      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Complement Naive Bayes\n",
    "cnb = ComplementNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "y_pred = cnb.predict(X_val)\n",
    "\n",
    "print('Getting the Best Model Performance' + '\\n')\n",
    "print('Accuracy: {}'.format(accuracy_score(y_val, y_pred)))\n",
    "print('F1: {}'.format(f1_score(y_val, y_pred, average='macro')))\n",
    "print('\\n' + classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrying out cross-validation and checking F1 score for different classifiers\n",
    "random_state = 42\n",
    "kf = KFold(n_splits=10,\n",
    "           random_state=random_state,\n",
    "           shuffle=True)  # Define number of KFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': [0.1, 0.5, 1, 10],\n",
    "          'norm': [True, False]}\n",
    "\n",
    "clf2 = GridSearchCV(ComplementNB(),\n",
    "                    param_grid=params,\n",
    "                    cv=kf,\n",
    "                    scoring=make_scorer(f1_score,\n",
    "                                        average='macro'))\n",
    "# Fit the gridsearch on the dataset\n",
    "clf2 = clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the Best Model Performance\n",
      "\n",
      "Accuracy: 0.9975757575757576\n",
      "F1: 0.9976053957960019\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       0.99      1.00      1.00       281\n",
      "         eng       1.00      1.00      1.00       297\n",
      "         nbl       0.99      1.00      1.00       327\n",
      "         nso       1.00      0.99      1.00       322\n",
      "         sot       0.99      1.00      1.00       307\n",
      "         ssw       1.00      1.00      1.00       286\n",
      "         tsn       1.00      1.00      1.00       297\n",
      "         tso       1.00      1.00      1.00       253\n",
      "         ven       1.00      1.00      1.00       322\n",
      "         xho       1.00      1.00      1.00       313\n",
      "         zul       1.00      0.99      0.99       295\n",
      "\n",
      "    accuracy                           1.00      3300\n",
      "   macro avg       1.00      1.00      1.00      3300\n",
      "weighted avg       1.00      1.00      1.00      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf2.predict(X_val)\n",
    "\n",
    "print('Getting the Best Model Performance' + '\\n')\n",
    "print('Accuracy: {}'.format(accuracy_score(y_val, y_pred)))\n",
    "print('F1: {}'.format(f1_score(y_val, y_pred, average='macro')))\n",
    "print('\\n' + classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx = test['text']\n",
    "test_vect = vectorizer.transform(testx.values)\n",
    "# Predict the sentiment using the test data\n",
    "y_pred = clf2.predict(test_vect)\n",
    "# Assign a new column on the test data by using ...\n",
    "# the predicted sentiment from the tweets from test data\n",
    "test['lang_id'] = y_pred\n",
    "# Look into the data that will be submitted on Kaggle as csv\n",
    "test[['index', 'lang_id']].head()\n",
    "# save the csv file and submit it.\n",
    "test[['index', 'lang_id']].to_csv('test_ComplementNB_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnb = ComplementNB(alpha=clf2.best_params_['alpha'],\n",
    "                   norm=clf2.best_params_['norm'])\n",
    "cnb.fit(X_train, y_train)\n",
    "y_pred = cnb.predict(X_val)\n",
    "\n",
    "cnb_tuned = ComplementNB()\n",
    "cnb_tuned.fit(X_train, y_train)\n",
    "y_pred_tuned = cnb_tuned.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx = test['text']\n",
    "test_vect = vectorizer.transform(testx.values)\n",
    "# Predict the sentiment using the test data\n",
    "y_pred = cnb.predict(test_vect)\n",
    "# Assign a new column on the test data by using ...\n",
    "# the predicted sentiment from the tweets from test data\n",
    "test['lang_id'] = y_pred\n",
    "# Look into the data that will be submitted on Kaggle as csv\n",
    "test[['index', 'lang_id']].head()\n",
    "# save the csv file and submit it.\n",
    "test[['index', 'lang_id']].to_csv('test_ComplementNBtuned_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the Best Model Performance\n",
      "\n",
      "Accuracy: 0.9972727272727273\n",
      "F1: 0.9973020448773352\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       281\n",
      "         eng       1.00      1.00      1.00       297\n",
      "         nbl       1.00      0.99      1.00       327\n",
      "         nso       1.00      0.99      1.00       322\n",
      "         sot       0.99      1.00      1.00       307\n",
      "         ssw       1.00      1.00      1.00       286\n",
      "         tsn       1.00      1.00      1.00       297\n",
      "         tso       1.00      1.00      1.00       253\n",
      "         ven       1.00      1.00      1.00       322\n",
      "         xho       0.99      1.00      1.00       313\n",
      "         zul       0.99      1.00      0.99       295\n",
      "\n",
      "    accuracy                           1.00      3300\n",
      "   macro avg       1.00      1.00      1.00      3300\n",
      "weighted avg       1.00      1.00      1.00      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify the range of 'C' parameters for LinearSVC\n",
    "params = {'C': [0.1, 0.5, 1, 5, 10]}\n",
    "\n",
    "# Setting the GridSearch for the best parameters\n",
    "clf = GridSearchCV(LinearSVC(max_iter=4000, multi_class='ovr'),\n",
    "                   param_grid=params, cv=kf,\n",
    "                   scoring=make_scorer(f1_score, average='macro'))\n",
    "\n",
    "# Fit the gridsearch on the dataset\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print('Getting the Best Model Performance' + '\\n')\n",
    "print('Accuracy: {}'.format(accuracy_score(y_val, y_pred)))\n",
    "print('F1: {}'.format(f1_score(y_val, y_pred, average='macro')))\n",
    "print('\\n' + classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx = test['text']\n",
    "test_vect = vectorizer.transform(testx.values)\n",
    "# Predict the sentiment using the test data\n",
    "y_pred = clf.predict(test_vect)\n",
    "# Assign a new column on the test data by using ...\n",
    "# the predicted sentiment from the tweets from test data\n",
    "test['lang_id'] = y_pred\n",
    "# Look into the data that will be submitted on Kaggle as csv\n",
    "test[['index', 'lang_id']].head()\n",
    "# save the csv file and submit it.\n",
    "test[['index', 'lang_id']].to_csv('test_LinearSVC_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}