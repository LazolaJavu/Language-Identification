{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Metrics for Model Evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikitplot.metrics import plot_roc, plot_confusion_matrix\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"train_set.csv\")\n",
    "samp_sub = pd.read_csv(\"sample_submission.csv\")\n",
    "data_test = pd.read_csv(\"test_set.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = data_test.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the train data\n",
    "data_train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eng    3000\n",
       "nso    3000\n",
       "tso    3000\n",
       "ssw    3000\n",
       "ven    3000\n",
       "zul    3000\n",
       "nbl    3000\n",
       "xho    3000\n",
       "tsn    3000\n",
       "sot    3000\n",
       "afr    3000\n",
       "Name: lang_id, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the values of the language id:\n",
    "data_train[\"lang_id\"].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang_id    0\n",
       "text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for the null values in the dataset\n",
    "data_train.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta."
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the test data\n",
    "data_test.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index lang_id\n",
       "0      1     tsn\n",
       "1      2     nbl"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the sample data, i.e. how we will have to submit...\n",
    "samp_sub.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['xho', 'eng', 'nso', 'ven', 'tsn', 'nbl', 'zul', 'ssw', 'tso',\n",
       "       'sot', 'afr'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the unique values of the train dataset language id\n",
    "data_train[\"lang_id\"].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    2,    3, ..., 5680, 5681, 5682], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the unique values of the test dataset index\n",
    "data_test[\"index\"].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_sub[\"index\"].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the train dataset\n",
    "df = data_train.copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['xho', 'eng', 'nso', 'ven', 'tsn', 'nbl', 'zul', 'ssw', 'tso',\n",
       "       'sot', 'afr'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['lang_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_text(text):\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL', text)\n",
    "    text = re.sub('@[^\\s]+','USER', text)\n",
    "    text = text.lower().replace(\"ё\", \"е\")\n",
    "    text = re.sub('[^a-zA-Zа-яА-Я1-9]+', ' ', text)\n",
    "    text = re.sub(' +',' ', text)\n",
    "    return text.strip()\n",
    "df[\"text1\"] = [preprocess_text(t) for t in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "      <th>text1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>umgaqo siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>i dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>the province of kwazulu natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>o netefat a gore o ba file dilo ka moka t e le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32995</th>\n",
       "      <td>tsn</td>\n",
       "      <td>popo ya dipolateforomo tse ke go tlisa boetele...</td>\n",
       "      <td>popo ya dipolateforomo tse ke go tlisa boetele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32996</th>\n",
       "      <td>sot</td>\n",
       "      <td>modise mosadi na o ntse o sa utlwe hore thaban...</td>\n",
       "      <td>modise mosadi na o ntse o sa utlwe hore thaban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32997</th>\n",
       "      <td>eng</td>\n",
       "      <td>closing date for the submission of completed t...</td>\n",
       "      <td>closing date for the submission of completed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32998</th>\n",
       "      <td>xho</td>\n",
       "      <td>nawuphina umntu ofunyenwe enetyala phantsi kwa...</td>\n",
       "      <td>nawuphina umntu ofunyenwe enetyala phantsi kwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32999</th>\n",
       "      <td>sot</td>\n",
       "      <td>mafapha a mang le ona a lokela ho etsa ditlale...</td>\n",
       "      <td>mafapha a mang le ona a lokela ho etsa ditlale...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lang_id                                               text  \\\n",
       "0         xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...   \n",
       "1         xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2         eng  the province of kwazulu-natal department of tr...   \n",
       "3         nso  o netefatša gore o ba file dilo ka moka tše le...   \n",
       "4         ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "...       ...                                                ...   \n",
       "32995     tsn  popo ya dipolateforomo tse ke go tlisa boetele...   \n",
       "32996     sot  modise mosadi na o ntse o sa utlwe hore thaban...   \n",
       "32997     eng  closing date for the submission of completed t...   \n",
       "32998     xho  nawuphina umntu ofunyenwe enetyala phantsi kwa...   \n",
       "32999     sot  mafapha a mang le ona a lokela ho etsa ditlale...   \n",
       "\n",
       "                                                   text1  \n",
       "0      umgaqo siseko wenza amalungiselelo kumaziko ax...  \n",
       "1      i dha iya kuba nobulumko bokubeka umsebenzi na...  \n",
       "2      the province of kwazulu natal department of tr...  \n",
       "3      o netefat a gore o ba file dilo ka moka t e le...  \n",
       "4      khomishini ya ndinganyiso ya mbeu yo ewa maana...  \n",
       "...                                                  ...  \n",
       "32995  popo ya dipolateforomo tse ke go tlisa boetele...  \n",
       "32996  modise mosadi na o ntse o sa utlwe hore thaban...  \n",
       "32997  closing date for the submission of completed t...  \n",
       "32998  nawuphina umntu ofunyenwe enetyala phantsi kwa...  \n",
       "32999  mafapha a mang le ona a lokela ho etsa ditlale...  \n",
       "\n",
       "[33000 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate features and tagret variables\n",
    "y = df['lang_id']\n",
    "X = df['text1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning text into something your model can read\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=2)\n",
    "X_vectorized = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train data to create validation dataset\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_vectorized,y,test_size=.2,shuffle=True, stratify=y, random_state=11)#changed test size to 0.1 from 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9986363636363637\n"
     ]
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred = nb_model.predict(X_val)\n",
    "nb_model_f1 = round(f1_score(y_val, y_pred, average='weighted'),2)\n",
    "print('Accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "\n",
    "report = classification_report(y_val, y_pred, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_text(text):\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL', text)\n",
    "    text = re.sub('@[^\\s]+','USER', text)\n",
    "    text = text.lower().replace(\"ё\", \"е\")\n",
    "    text = re.sub('[^a-zA-Zа-яА-Я1-9]+', ' ', text)\n",
    "    text = re.sub(' +',' ', text)\n",
    "    return text.strip()\n",
    "df_test[\"text1\"] = [preprocess_text(t) for t in data_test['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nb = df_test[\"text1\"]\n",
    "test_vect = vectorizer.transform(test_nb)\n",
    "# Predict the sentiment using the test data\n",
    "y_pred = nb_model.predict(test_vect)\n",
    "# Assign a new column on the test data by using ...\n",
    "# the predicted sentiment from the tweets from test data\n",
    "data_test['lang_id'] = y_pred\n",
    "# Look into the data that will be submitted on Kaggle as csv\n",
    "data_test[['index', 'lang_id']].head()\n",
    "# save the csv file and submit it.\n",
    "data_test[['index', 'lang_id']].to_csv('test_nb_model_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9971212121212121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'afr': {'precision': 0.9983361064891847,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.9991673605328892,\n",
       "  'support': 600},\n",
       " 'eng': {'precision': 0.9966777408637874,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.9983361064891847,\n",
       "  'support': 600},\n",
       " 'nbl': {'precision': 0.9933444259567388,\n",
       "  'recall': 0.995,\n",
       "  'f1-score': 0.9941715237302248,\n",
       "  'support': 600},\n",
       " 'nso': {'precision': 0.9966777408637874,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.9983361064891847,\n",
       "  'support': 600},\n",
       " 'sot': {'precision': 1.0,\n",
       "  'recall': 0.9983333333333333,\n",
       "  'f1-score': 0.9991659716430359,\n",
       "  'support': 600},\n",
       " 'ssw': {'precision': 0.9950166112956811,\n",
       "  'recall': 0.9983333333333333,\n",
       "  'f1-score': 0.9966722129783694,\n",
       "  'support': 600},\n",
       " 'tsn': {'precision': 1.0,\n",
       "  'recall': 0.9966666666666667,\n",
       "  'f1-score': 0.9983305509181971,\n",
       "  'support': 600},\n",
       " 'tso': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 600},\n",
       " 'ven': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 600},\n",
       " 'xho': {'precision': 0.9966555183946488,\n",
       "  'recall': 0.9933333333333333,\n",
       "  'f1-score': 0.9949916527545909,\n",
       "  'support': 600},\n",
       " 'zul': {'precision': 0.9916247906197655,\n",
       "  'recall': 0.9866666666666667,\n",
       "  'f1-score': 0.9891395154553049,\n",
       "  'support': 600},\n",
       " 'accuracy': 0.9971212121212121,\n",
       " 'macro avg': {'precision': 0.9971211758621448,\n",
       "  'recall': 0.9971212121212122,\n",
       "  'f1-score': 0.9971191819082711,\n",
       "  'support': 6600},\n",
       " 'weighted avg': {'precision': 0.9971211758621449,\n",
       "  'recall': 0.9971212121212121,\n",
       "  'f1-score': 0.9971191819082712,\n",
       "  'support': 6600}}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "linsvc = LinearSVC()\n",
    "linsvc.fit(X_train, y_train)\n",
    "y_pred = linsvc.predict(X_val)\n",
    "linsvc_f1 = round(f1_score(y_val, y_pred, average='weighted'),2)\n",
    "print('Accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "\n",
    "report = classification_report(y_val, y_pred, output_dict=True)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nb = df_test[\"text1\"]\n",
    "test_vect = vectorizer.transform(test_nb)\n",
    "# Predict the sentiment using the test data\n",
    "y_pred = linsvc.predict(test_vect)\n",
    "# Assign a new column on the test data by using ...\n",
    "# the predicted sentiment from the tweets from test data\n",
    "data_test['lang_id'] = y_pred\n",
    "# Look into the data that will be submitted on Kaggle as csv\n",
    "data_test[['index', 'lang_id']].head()\n",
    "# save the csv file and submit it.\n",
    "data_test[['index', 'lang_id']].to_csv('test_linsvc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 10 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   59.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=15, estimator=MultinomialNB(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
       "                                   1.0]},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "         }\n",
    "\n",
    "multinomial_nb_grid = GridSearchCV(MultinomialNB(), param_grid=params, n_jobs=-1, cv=15, verbose=5)\n",
    "multinomial_nb_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nb = df_test[\"text1\"]\n",
    "test_vect = vectorizer.transform(test_nb)\n",
    "# Predict the sentiment using the test data\n",
    "y_pred = multinomial_nb_grid.predict(test_vect)\n",
    "# Assign a new column on the test data by using ...\n",
    "# the predicted sentiment from the tweets from test data\n",
    "data_test['lang_id'] = y_pred\n",
    "# Look into the data that will be submitted on Kaggle as csv\n",
    "data_test[['index', 'lang_id']].head()\n",
    "# save the csv file and submit it.\n",
    "data_test[['index', 'lang_id']].to_csv('test_multinomial.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-a8171034b9d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m kf = KFold(n_splits=10,\n\u001b[0m\u001b[0;32m      3\u001b[0m            \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m            shuffle=True)  # Define number of KFolds\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KFold' is not defined"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "kf = KFold(n_splits=10,\n",
    "           random_state=random_state,\n",
    "           shuffle=True)  # Define number of KFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-374944d85140>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Setting the GridSearch for the best parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m clf = GridSearchCV(LinearSVC(max_iter=4000, multi_class='ovr'),\n\u001b[1;32m----> 6\u001b[1;33m                    \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                    scoring=make_scorer(f1_score, average='macro'))\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kf' is not defined"
     ]
    }
   ],
   "source": [
    "# Specify the range of 'C' parameters for LinearSVC\n",
    "params = {'C': [0.1, 0.5, 1, 5, 10]}\n",
    "\n",
    "# Setting the GridSearch for the best parameters\n",
    "clf = GridSearchCV(LinearSVC(max_iter=4000, multi_class='ovr'),\n",
    "                   param_grid=params, cv=kf,\n",
    "                   scoring=make_scorer(f1_score, average='macro'))\n",
    "\n",
    "# Fit the gridsearch on the dataset\n",
    "clf = clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate features and tagret variables\n",
    "y = df['lang_id'].values\n",
    "X = df['text1'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train data to create validation dataset\n",
    "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=.2,shuffle=True, stratify=y, random_state=11)#changed test size to 0.1 from 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pipenb = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df=3, max_features=None,\n",
    "                              strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',\n",
    "                              ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1)),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(min_df=3, ngram_range=(1, 3), smooth_idf=1,\n",
       "                                 strip_accents='unicode', sublinear_tf=1,\n",
       "                                 token_pattern='\\\\w{1,}', use_idf=1)),\n",
       "                ('mnb', MultinomialNB())])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_pipenb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nb = tfidf_pipenb.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       600\n",
      "         eng       0.99      1.00      1.00       600\n",
      "         nbl       1.00      0.99      1.00       600\n",
      "         nso       1.00      1.00      1.00       600\n",
      "         sot       1.00      1.00      1.00       600\n",
      "         ssw       1.00      1.00      1.00       600\n",
      "         tsn       1.00      1.00      1.00       600\n",
      "         tso       1.00      1.00      1.00       600\n",
      "         ven       1.00      1.00      1.00       600\n",
      "         xho       1.00      1.00      1.00       600\n",
      "         zul       0.99      0.99      0.99       600\n",
      "\n",
      "    accuracy                           1.00      6600\n",
      "   macro avg       1.00      1.00      1.00      6600\n",
      "weighted avg       1.00      1.00      1.00      6600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nb = df_test[\"text1\"]\n",
    "#test_vect = vectorizer.transform(test_nb)\n",
    "# Predict the sentiment using the test data\n",
    "y_pred = tfidf_pipenb.predict(test_nb)\n",
    "# Assign a new column on the test data by using ...\n",
    "# the predicted sentiment from the tweets from test data\n",
    "data_test['lang_id'] = y_pred\n",
    "# Look into the data that will be submitted on Kaggle as csv\n",
    "data_test[['index', 'lang_id']].head()\n",
    "# save the csv file and submit it.\n",
    "data_test[['index', 'lang_id']].to_csv('test_pipeline_nb_model_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
